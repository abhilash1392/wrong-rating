{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('ml': conda)",
   "metadata": {
    "interpreter": {
     "hash": "2c424111344ada7f9bd2b2eff03ee5c13ec854e09fa2742d5c615273b4cc491a"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     ID                                         Review URL  \\\n",
       "0  3886  https://play.google.com/store/apps/details?id=...   \n",
       "1  3887  https://play.google.com/store/apps/details?id=...   \n",
       "2  3888  https://play.google.com/store/apps/details?id=...   \n",
       "3  3889  https://play.google.com/store/apps/details?id=...   \n",
       "4  3890  https://play.google.com/store/apps/details?id=...   \n",
       "\n",
       "                                             Text  Star  Thumbs Up  \\\n",
       "0                      This is very helpfull aap.     5          0   \n",
       "1                                            Good     3          2   \n",
       "2  Not able to update. Neither able to uninstall.     1          0   \n",
       "3                                        Nice app     4          0   \n",
       "4                               Many unwanted ads     1          0   \n",
       "\n",
       "          User Name Developer Reply        Version Review Date  \\\n",
       "0  INDIAN Knowledge             NaN  83.0.4103.106  2020-12-19   \n",
       "1  Ijeoma Happiness             NaN  85.0.4183.127  2020-12-19   \n",
       "2  Priti D BtCFs-29             NaN  85.0.4183.127  2020-12-19   \n",
       "3        Ajeet Raja             NaN  77.0.3865.116  2020-12-19   \n",
       "4           Rams Mp             NaN   87.0.4280.66  2020-12-19   \n",
       "\n",
       "               App ID  \n",
       "0  com.android.chrome  \n",
       "1  com.android.chrome  \n",
       "2  com.android.chrome  \n",
       "3  com.android.chrome  \n",
       "4  com.android.chrome  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Review URL</th>\n      <th>Text</th>\n      <th>Star</th>\n      <th>Thumbs Up</th>\n      <th>User Name</th>\n      <th>Developer Reply</th>\n      <th>Version</th>\n      <th>Review Date</th>\n      <th>App ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3886</td>\n      <td>https://play.google.com/store/apps/details?id=...</td>\n      <td>This is very helpfull aap.</td>\n      <td>5</td>\n      <td>0</td>\n      <td>INDIAN Knowledge</td>\n      <td>NaN</td>\n      <td>83.0.4103.106</td>\n      <td>2020-12-19</td>\n      <td>com.android.chrome</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3887</td>\n      <td>https://play.google.com/store/apps/details?id=...</td>\n      <td>Good</td>\n      <td>3</td>\n      <td>2</td>\n      <td>Ijeoma Happiness</td>\n      <td>NaN</td>\n      <td>85.0.4183.127</td>\n      <td>2020-12-19</td>\n      <td>com.android.chrome</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3888</td>\n      <td>https://play.google.com/store/apps/details?id=...</td>\n      <td>Not able to update. Neither able to uninstall.</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Priti D BtCFs-29</td>\n      <td>NaN</td>\n      <td>85.0.4183.127</td>\n      <td>2020-12-19</td>\n      <td>com.android.chrome</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3889</td>\n      <td>https://play.google.com/store/apps/details?id=...</td>\n      <td>Nice app</td>\n      <td>4</td>\n      <td>0</td>\n      <td>Ajeet Raja</td>\n      <td>NaN</td>\n      <td>77.0.3865.116</td>\n      <td>2020-12-19</td>\n      <td>com.android.chrome</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3890</td>\n      <td>https://play.google.com/store/apps/details?id=...</td>\n      <td>Many unwanted ads</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Rams Mp</td>\n      <td>NaN</td>\n      <td>87.0.4280.66</td>\n      <td>2020-12-19</td>\n      <td>com.android.chrome</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df = pd.read_csv('chrome_reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Text','Star']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(7204, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(7203, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5    3870\n",
       "1    1894\n",
       "4     652\n",
       "3     451\n",
       "2     336\n",
       "Name: Star, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df.Star.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import string \n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Removing the punctutation\n",
    "    text_lc = \"\".join([word.lower() for word in text if word not in string.punctuation ])\n",
    "    # Removing the numbers\n",
    "    text_rc = re.sub('[0-9]+','',str(text_lc))\n",
    "    # tokenizing using TweetTokenizer\n",
    "    tokens = word_tokenize(text_rc)\n",
    "    stopword = nltk.corpus.stopwords.words('english')\n",
    "    new_words = ['chrome','app','google','browser']\n",
    "    stopword.extend(new_words)\n",
    "    text = [word for word in tokens if word not in stopword]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvt = CountVectorizer(preprocessor=clean_text)\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "pipe = make_pipeline(cvt,kmeans)\n",
    "y = pipe.fit_predict(df.Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer',\n",
       "                 CountVectorizer(preprocessor=<function clean_text at 0x7f60cb1950e0>)),\n",
       "                ('kneighborsclassifier', KNeighborsClassifier())])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "pipe2 = make_pipeline(cvt,knn)\n",
    "pipe2.fit(df.Text,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 1], dtype=int32)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0], dtype=int32)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "y_pred = pipe2.predict(['So Good'])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
    "terms  = cvt.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cluster:  0\n good\n nice\n best\n great\n ok\n like\n love\n updating\n use\n excellent\nCluster:  1\n update\n cant\n wont\n able\n unable\n please\n new\n problem\n dont\n even\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(\"Cluster: \",i)\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(\" %s\" %  terms[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = joblib.load('model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "n_samples=1 should be >= n_clusters=5.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-5db414aa27fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mxtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'This is so good'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_predict\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    453\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[1;32m    454\u001b[0m             y_pred = self.steps[-1][-1].fit_predict(Xt, y,\n\u001b[0;32m--> 455\u001b[0;31m                                                     **fit_params_last_step)\n\u001b[0m\u001b[1;32m    456\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36mfit_predict\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1075\u001b[0m             \u001b[0mIndex\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m \u001b[0mbelongs\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m         \"\"\"\n\u001b[0;32m-> 1077\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    982\u001b[0m                                 accept_large_sparse=False)\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    985\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36m_check_params\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;31m# n_clusters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m             raise ValueError(f\"n_samples={X.shape[0]} should be >= \"\n\u001b[0m\u001b[1;32m    813\u001b[0m                              f\"n_clusters={self.n_clusters}.\")\n\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: n_samples=1 should be >= n_clusters=5."
     ]
    }
   ],
   "source": [
    "xtest = 'This is so good'\n",
    "pred = load_model.fit_predict([xtest])\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Iterable over raw text documents expected, string object received.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-2c3cdeeb1b55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcvt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m             raise ValueError(\n\u001b[0;32m-> 1194\u001b[0;31m                 \u001b[0;34m\"Iterable over raw text documents expected, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m                 \"string object received.\")\n\u001b[1;32m   1196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Iterable over raw text documents expected, string object received."
     ]
    }
   ],
   "source": [
    "x_t = cvt.fit_transform(text)\n",
    "x_t"
   ]
  }
 ]
}